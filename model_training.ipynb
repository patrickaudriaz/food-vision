{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs329s-ml-model-deployment-model-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpc09/rMn9nAU9Op2f/zuH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.1 64-bit"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTWetPM7AWfY"
      },
      "source": [
        "# Let's train some models to deploy...\n",
        "\n",
        "* **Want:** [`SavedModel`](https://www.tensorflow.org/guide/saved_model) format to upload to Google Storage (GS).\n",
        "* **Data:** Different slices of [Food101 dataset](https://www.kaggle.com/dansbecker/food-101).\n",
        "* **Model(s):** [EfficientNetB0](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0) backbone's with different output layers (e.g. 10 classes, 11 classes, 12 classes).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq4kxIpQMpZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7de6e3-17fb-4334-9619-8f9437c8c798"
      },
      "source": [
        "# Are we using a GPU? \n",
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul  9 16:37:55 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 466.77       Driver Version: 466.77       CUDA Version: 11.3     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ... WDDM  | 00000000:2B:00.0 Off |                  N/A |\n| N/A   59C    P8    N/A /  N/A |     64MiB /  2048MiB |      1%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk-UIzd_SA5T"
      },
      "source": [
        "## Setup helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9IdsOGuLYVK"
      },
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Unzip the downloaded file\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Utility function to unzip a zipped file.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_1Ol5LZXrb8"
      },
      "source": [
        "# Setup data inputs\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def create_data_loaders(train_dir, test_dir, image_size=IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Creates a training and test image BatchDataset from train_dir and test_dir.\n",
        "  \"\"\"\n",
        "  train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "  # Note: the test data is the same as the previous experiment, we could\n",
        "  # skip creating this, but we'll leave this here to practice.\n",
        "  test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "  \n",
        "  return train_data, test_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Icsoq0YYRb"
      },
      "source": [
        "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
        "data_augmentation = keras.Sequential([\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomZoom(0.2),\n",
        "  preprocessing.RandomHeight(0.2),\n",
        "  preprocessing.RandomWidth(0.2),\n",
        "  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
        "], name =\"data_augmentation\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn5qDRF8XqLs",
        "outputId": "ef83fb12-64a5-4401-f5da-b1485fb91d3a"
      },
      "source": [
        "# Setup input shape and base model, freezing the base model layers\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "BASE_MODEL = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "def create_model(input_shape=INPUT_SHAPE, base_model=BASE_MODEL, num_classes=10):\n",
        "  # Fine-tune?\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # Create input layer\n",
        "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "  # Add in data augmentation Sequential model as a layer\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  # Give base_model inputs (after augmentation) and don't train it\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  # Pool output features of base model\n",
        "  x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "\n",
        "  # Put a dense layer on as the output\n",
        "  outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "  # Make a model with inputs and outputs\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5w0PI1pOl7I"
      },
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=False):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  if scale:\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIwVrX6vXb4z"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwWwP657Szfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004ed027-ab11-4541-c95d-f912779a8c81"
      },
      "source": [
        "# Get data\n",
        "import zipfile\n",
        "\n",
        "# Download data (10 class subset of Food101 - https://www.kaggle.com/dansbecker/food-101)\n",
        "# Already formatted in standard image classification directory style\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_all_datas.zip\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agzJYtfFBl6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da62030b-260b-479d-e71c-14c20b65b39b"
      },
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_all_data'.\nThere are 10 directories and 0 images in '10_food_classes_all_data\\test'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\chicken_curry'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\chicken_wings'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\fried_rice'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\grilled_salmon'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\hamburger'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\ice_cream'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\pizza'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\ramen'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\steak'.\nThere are 0 directories and 250 images in '10_food_classes_all_data\\test\\sushi'.\nThere are 10 directories and 0 images in '10_food_classes_all_data\\train'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\chicken_curry'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\chicken_wings'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\fried_rice'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\grilled_salmon'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\hamburger'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\ice_cream'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\pizza'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\ramen'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\steak'.\nThere are 0 directories and 750 images in '10_food_classes_all_data\\train\\sushi'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34VT7QiuL7Il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df6609b-3511-466e-9810-3e84a6847d6e"
      },
      "source": [
        "# Check the file in 10_food_classes_10_percent\n",
        "!ls -la 10_food_classes_all_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 28\n",
            "drwxr-xr-x  4 root root 4096 Feb 14 05:54 .\n",
            "drwxr-xr-x  1 root root 4096 Feb 14 05:54 ..\n",
            "-rw-r--r--  1 root root 8196 Feb 14 05:54 .DS_Store\n",
            "drwxr-xr-x 12 root root 4096 Feb 14 05:54 test\n",
            "drwxr-xr-x 12 root root 4096 Feb 14 05:54 train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yamhJ8xJA5x"
      },
      "source": [
        "# Create tensorboard callback (functionized because need to create a new one for each model)\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11TjBJQXdCyZ"
      },
      "source": [
        "* `dir_name` is the overall logs directory\n",
        "* `experiment_name` is the particular experiment\n",
        "* `current_timestamp` is the time the experiment started based on Python's [`datetime.datetime().now()`](https://docs.python.org/3/library/datetime.html#datetime.datetime.now)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mXArGOXXn6P"
      },
      "source": [
        "## Model (10 classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwrIl-rsLdz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015faef0-2406-4f24-85bc-6a0bf64f8191"
      },
      "source": [
        "# Create BatchDataset\n",
        "train_data, test_data = create_data_loaders(train_dir=\"10_food_classes_all_data/train/\",\n",
        "                                            test_dir=\"10_food_classes_all_data/test/\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 files belonging to 10 classes.\nFound 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_h12Aozqge7",
        "outputId": "530c6a46-be30-4fa3-ad6d-fc76e840eb7c"
      },
      "source": [
        "# What size is our data?\n",
        "train_data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSo9wTmBy6zr",
        "outputId": "f2b95a59-16f7-4efa-9cda-4b6aced9e961"
      },
      "source": [
        "# Create model\n",
        "model_1 = create_model(num_classes=len(train_data.class_names))\n",
        "\n",
        "# Fit the model\n",
        "history_1_percent = model_1.fit(train_data,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=len(train_data),\n",
        "                    validation_data=test_data,\n",
        "                    validation_steps=int(0.25 * len(test_data)), # validate for less steps\n",
        "                    # Track model training logs\n",
        "                    callbacks=[create_tensorboard_callback(\"transfer_learning\", \"all_data_aug\")])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: transfer_learning/all_data_aug/20210709-164936\n",
            "C:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  warnings.warn('Custom mask layers require a config and must override '\n",
            "Epoch 1/5\n",
            "235/235 [==============================] - 278s 1s/step - loss: 1.0708 - accuracy: 0.6880 - val_loss: 0.5016 - val_accuracy: 0.8503\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 244s 1s/step - loss: 0.6838 - accuracy: 0.7827 - val_loss: 0.4203 - val_accuracy: 0.8684\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 253s 1s/step - loss: 0.6133 - accuracy: 0.8096 - val_loss: 0.3868 - val_accuracy: 0.8799\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 265s 1s/step - loss: 0.5654 - accuracy: 0.8187 - val_loss: 0.3834 - val_accuracy: 0.8783\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 262s 1s/step - loss: 0.5375 - accuracy: 0.8268 - val_loss: 0.3775 - val_accuracy: 0.8849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUKJxKVaY3aA",
        "outputId": "2aa249cd-9223-41b7-b9ee-0490b5f49ab0"
      },
      "source": [
        "# Get an image Tensor\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-10 23:18:11--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2874848 (2.7M) [image/jpeg]\n",
            "Saving to: ‘03-pizza-dad.jpeg’\n",
            "\n",
            "03-pizza-dad.jpeg   100%[===================>]   2.74M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-02-10 23:18:11 (27.7 MB/s) - ‘03-pizza-dad.jpeg’ saved [2874848/2874848]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3SwO_LAqHAM",
        "outputId": "61055710-bec2-4832-a753-1cb576444c27"
      },
      "source": [
        "# Classes our model is trained on\n",
        "class_names = train_data.class_names\n",
        "class_names"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7gCXuavaDAF",
        "outputId": "2c7775a9-8c87-4409-dcb5-589226d1912d"
      },
      "source": [
        "# Preprocess image\n",
        "pizza_img = load_and_prep_image(\"03-pizza-dad.jpeg\")\n",
        "pizza_img"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
              "array([[[ 73.625,  76.75 ,  67.125],\n",
              "        [114.   , 122.   , 101.   ],\n",
              "        [146.875, 151.875, 129.875],\n",
              "        ...,\n",
              "        [ 14.5  ,  17.5  ,  10.5  ],\n",
              "        [ 14.25 ,  19.25 ,  12.25 ],\n",
              "        [ 19.75 ,  22.75 ,  15.75 ]],\n",
              "\n",
              "       [[239.125, 243.625, 246.125],\n",
              "        [225.375, 232.125, 234.875],\n",
              "        [240.   , 245.   , 244.5  ],\n",
              "        ...,\n",
              "        [ 11.   ,  14.   ,   7.   ],\n",
              "        [ 20.   ,  23.   ,  16.   ],\n",
              "        [ 20.875,  25.875,  18.875]],\n",
              "\n",
              "       [[ 32.5  ,  34.5  ,  31.5  ],\n",
              "        [ 44.625,  44.5  ,  42.375],\n",
              "        [ 33.   ,  38.   ,  34.   ],\n",
              "        ...,\n",
              "        [  8.75 ,  13.25 ,   6.25 ],\n",
              "        [ 14.875,  17.875,  10.875],\n",
              "        [ 13.625,  20.625,  12.625]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 61.875,  40.875,  19.875],\n",
              "        [ 60.   ,  42.   ,  22.   ],\n",
              "        [ 61.   ,  43.   ,  21.   ],\n",
              "        ...,\n",
              "        [134.5  ,  96.125,  60.75 ],\n",
              "        [104.875,  69.375,  43.125],\n",
              "        [106.25 ,  75.25 ,  46.25 ]],\n",
              "\n",
              "       [[ 62.75 ,  44.75 ,  24.75 ],\n",
              "        [ 61.125,  43.125,  23.125],\n",
              "        [ 58.125,  40.125,  20.125],\n",
              "        ...,\n",
              "        [159.125, 111.125,  64.625],\n",
              "        [160.375, 112.375,  66.375],\n",
              "        [134.   ,  94.125,  56.75 ]],\n",
              "\n",
              "       [[ 59.625,  42.625,  22.625],\n",
              "        [ 61.75 ,  43.75 ,  22.5  ],\n",
              "        [ 59.25 ,  41.25 ,  21.25 ],\n",
              "        ...,\n",
              "        [161.5  , 113.5  ,  64.5  ],\n",
              "        [159.   , 108.   ,  63.   ],\n",
              "        [155.875, 104.875,  59.875]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81z-ynOlabav",
        "outputId": "4e9ed977-5b2a-4e6d-85e5-9fab2680f8ef"
      },
      "source": [
        "# Make predictions\n",
        "pizza_expanded = tf.expand_dims(pizza_img, axis=0) # expand image dimensions (224, 224, 3) -> (1, 224, 224, 3)\n",
        "pred = model_1.predict(pizza_expanded)\n",
        "pred"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1428705e-02, 1.1287200e-04, 4.7732206e-04, 1.0897476e-04,\n",
              "        4.2807296e-06, 1.0963952e-06, 9.8670828e-01, 1.4884207e-04,\n",
              "        1.3133651e-04, 8.7829010e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHIoie0Faoin",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6a85e7b-b9f1-42c5-a860-f79b127b8c04"
      },
      "source": [
        "# Check the predicted class\n",
        "class_names[tf.argmax(pred[0])]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pizza'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6mNxcPDqwQk"
      },
      "source": [
        "## Save and upload Model to Google Storage\n",
        "\n",
        "Upload the model to Google Storage using the following guide: https://cloud.google.com/storage/docs/uploading-objects#gsutil "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0jm4Hzdc85u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0e6b61-4624-4e41-bb95-afd58e94f49b"
      },
      "source": [
        "# Save model_1\n",
        "model_1.save(\"efficientnet_model_1_10_classes\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  warnings.warn('Custom mask layers require a config and must override '\n",
            "INFO:tensorflow:Assets written to: efficientnet_model_1_10_classes\\assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Xmp96WdkJD",
        "outputId": "77c962ea-9df1-45bf-b8c1-973affe473d0"
      },
      "source": [
        "# Copy model to bucket - https://cloud.google.com/storage/docs/uploading-objects#gsutil \n",
        "# Use \"-r\" for folders (r stands for recursive)\n",
        "!gsutil cp -r efficientnet_model_1_10_classes gs://patrick_ml_deployment_bucket"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'gsutil' n'est pas reconnu en tant que commande interne\nou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPzjTa_MwAHV",
        "outputId": "07dce2af-501b-4209-9ff1-30a225733f6c"
      },
      "source": [
        "# Copy model to bucket\n",
        "!gsutil cp -r efficientnet_model_1_10_classes gs://cs329s_live_bucket_creation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://efficientnet_model_1_10_classes/saved_model.pb [Content-Type=application/octet-stream]...\n",
            "Copying file://efficientnet_model_1_10_classes/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "Copying file://efficientnet_model_1_10_classes/variables/variables.index [Content-Type=application/octet-stream]...\n",
            "- [3 files][ 22.1 MiB/ 22.1 MiB]                                                \n",
            "Operation completed over 3 objects/22.1 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}